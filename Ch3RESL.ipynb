{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the F statistic (3.13) for dropping a single coefficient\n",
    "from a model is equal to the square of the corresponding z-score (3.12)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_1-p_0=1$, $RSS = (Y-X\\beta)^T(Y-X\\beta)$, \n",
    "\n",
    "$\\frac{(RSS_0-RSS_1)}{RSS_1/(N-p_1-1)} = \\beta_j^2/(\\sigma^2(X^TX)_j)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given data on two variables X and Y , consider fitting a cubic\n",
    "polynomial regression model $f(X) =\n",
    "\\sum^3_{j=0} β_jX_j$. In addition to plotting\n",
    "the fitted curve, you would like a 95% confidence band about the curve.\n",
    "Consider the following two approaches:\n",
    "1. At each point x_0, form a 95% confidence interval for the linear function\n",
    "$a^T\\beta =\\sum^3_{j=0} β_jx_j$\n",
    "\n",
    "2. Form a 95% confidence set for β as in (3.15), which in turn generates\n",
    "confidence intervals for f(x0).\n",
    "\n",
    "How do these approaches differ? Which band is likely to be wider? Conduct\n",
    "a small simulation experiment to compare the two methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach consider percentile for normal distribution for each $\\beta$. The second approach we consider percentile for chi distribution for set of $\\beta$s. I would expect second band to be wider all beta contribute at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>X</th><th scope=col>Y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>-1.0309190 </td><td>-0.51523722</td></tr>\n",
       "\t<tr><td>-0.9276214 </td><td>-0.91114062</td></tr>\n",
       "\t<tr><td> 0.4666954 </td><td> 1.09307322</td></tr>\n",
       "\t<tr><td>-0.9359402 </td><td>-2.84119599</td></tr>\n",
       "\t<tr><td>-0.6576590 </td><td> 0.05254111</td></tr>\n",
       "\t<tr><td> 1.5017470 </td><td> 7.69072953</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " X & Y\\\\\n",
       "\\hline\n",
       "\t -1.0309190  & -0.51523722\\\\\n",
       "\t -0.9276214  & -0.91114062\\\\\n",
       "\t  0.4666954  &  1.09307322\\\\\n",
       "\t -0.9359402  & -2.84119599\\\\\n",
       "\t -0.6576590  &  0.05254111\\\\\n",
       "\t  1.5017470  &  7.69072953\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| X | Y |\n",
       "|---|---|\n",
       "| -1.0309190  | -0.51523722 |\n",
       "| -0.9276214  | -0.91114062 |\n",
       "|  0.4666954  |  1.09307322 |\n",
       "| -0.9359402  | -2.84119599 |\n",
       "| -0.6576590  |  0.05254111 |\n",
       "|  1.5017470  |  7.69072953 |\n",
       "\n"
      ],
      "text/plain": [
       "  X          Y          \n",
       "1 -1.0309190 -0.51523722\n",
       "2 -0.9276214 -0.91114062\n",
       "3  0.4666954  1.09307322\n",
       "4 -0.9359402 -2.84119599\n",
       "5 -0.6576590  0.05254111\n",
       "6  1.5017470  7.69072953"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X=rnorm(20)\n",
    "Y = 2*X+X^2+0.6*X^3+rnorm(20)\n",
    "df = data.frame(X, Y)\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>2.5 %</th><th scope=col>97.5 %</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>-1.02638263</td><td>0.9926408  </td></tr>\n",
       "\t<tr><th scope=row>X</th><td> 0.38231752</td><td>3.0363725  </td></tr>\n",
       "\t<tr><th scope=row>I(X^2)</th><td> 0.04011944</td><td>5.2503809  </td></tr>\n",
       "\t<tr><th scope=row>I(X^3)</th><td> 0.12911475</td><td>2.8934194  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & 2.5 \\% & 97.5 \\%\\\\\n",
       "\\hline\n",
       "\t(Intercept) & -1.02638263 & 0.9926408  \\\\\n",
       "\tX &  0.38231752 & 3.0363725  \\\\\n",
       "\tI(X\\textasciicircum{}2) &  0.04011944 & 5.2503809  \\\\\n",
       "\tI(X\\textasciicircum{}3) &  0.12911475 & 2.8934194  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 2.5 % | 97.5 % |\n",
       "|---|---|---|\n",
       "| (Intercept) | -1.02638263 | 0.9926408   |\n",
       "| X |  0.38231752 | 3.0363725   |\n",
       "| I(X^2) |  0.04011944 | 5.2503809   |\n",
       "| I(X^3) |  0.12911475 | 2.8934194   |\n",
       "\n"
      ],
      "text/plain": [
       "            2.5 %       97.5 %   \n",
       "(Intercept) -1.02638263 0.9926408\n",
       "X            0.38231752 3.0363725\n",
       "I(X^2)       0.04011944 5.2503809\n",
       "I(X^3)       0.12911475 2.8934194"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = lm(Y~X+I(X^2)+I(X^3), data=df)\n",
    "confint(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gauss–Markov theorem:\n",
    "(a) Prove the Gauss–Markov theorem: the least squares estimate of a\n",
    "parameter $a^T$β has variance no bigger than that of any other linear\n",
    "unbiased estimate of $a^T$β (Section 3.2.2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let take estimater which differs from least square estimator by bector $b^T$. So that\n",
    "\n",
    "$E(c^T Y) = E(a^T\\beta+b^TY) = E(a^T\\beta) + E(b^tX\\beta)$\n",
    "\n",
    "because we have unbias estimator \n",
    "\n",
    "$=a^T\\beta$ Eq.(3.18)\n",
    "\n",
    "$b^TX = 0$, taking this into account to remove cross products\n",
    "\n",
    "$(c^Ty) = c^TVar(y)c = \\sigma^2 c^Tc = Var(a^T\\beta - b^TY)(a^T \\beta - b^TY)^T = \\sigma^2 (a^Ta/(X^TX)+b^Tb) > Var(a^T\\beta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
