{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the F statistic (3.13) for dropping a single coefficient\n",
    "from a model is equal to the square of the corresponding z-score (3.12)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_1-p_0=1$, $RSS = (Y-X\\beta)^T(Y-X\\beta)$, \n",
    "\n",
    "$\\frac{(RSS_0-RSS_1)}{RSS_1/(N-p_1-1)} = \\beta_j^2/(\\sigma^2(X^TX)_j)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given data on two variables X and Y , consider fitting a cubic\n",
    "polynomial regression model $f(X) =\n",
    "\\sum^3_{j=0} \\beta_jX_j$. In addition to plotting\n",
    "the fitted curve, you would like a 95% confidence band about the curve.\n",
    "Consider the following two approaches:\n",
    "1. At each point x_0, form a 95% confidence interval for the linear function\n",
    "$a^T\\beta =\\sum^3_{j=0} \\beta_jx_j$\n",
    "\n",
    "2. Form a 95% confidence set for β as in (3.15), which in turn generates\n",
    "confidence intervals for f(x0).\n",
    "\n",
    "How do these approaches differ? Which band is likely to be wider? Conduct\n",
    "a small simulation experiment to compare the two methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach consider percentile for normal distribution for each $\\beta$. The second approach we consider percentile for chi distribution for set of $\\beta$s. I would expect second band to be wider all beta contribute at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>X</th><th scope=col>Y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1.99676405</td><td>12.5180369 </td></tr>\n",
       "\t<tr><td> 0.14887276</td><td> 1.1051888 </td></tr>\n",
       "\t<tr><td> 0.02975812</td><td>-0.9762164 </td></tr>\n",
       "\t<tr><td>-0.10232201</td><td>-2.0374831 </td></tr>\n",
       "\t<tr><td> 1.30950677</td><td> 5.1682533 </td></tr>\n",
       "\t<tr><td>-1.64164290</td><td>-4.0566385 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " X & Y\\\\\n",
       "\\hline\n",
       "\t  1.99676405 & 12.5180369 \\\\\n",
       "\t  0.14887276 &  1.1051888 \\\\\n",
       "\t  0.02975812 & -0.9762164 \\\\\n",
       "\t -0.10232201 & -2.0374831 \\\\\n",
       "\t  1.30950677 &  5.1682533 \\\\\n",
       "\t -1.64164290 & -4.0566385 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| X | Y |\n",
       "|---|---|\n",
       "|  1.99676405 | 12.5180369  |\n",
       "|  0.14887276 |  1.1051888  |\n",
       "|  0.02975812 | -0.9762164  |\n",
       "| -0.10232201 | -2.0374831  |\n",
       "|  1.30950677 |  5.1682533  |\n",
       "| -1.64164290 | -4.0566385  |\n",
       "\n"
      ],
      "text/plain": [
       "  X           Y         \n",
       "1  1.99676405 12.5180369\n",
       "2  0.14887276  1.1051888\n",
       "3  0.02975812 -0.9762164\n",
       "4 -0.10232201 -2.0374831\n",
       "5  1.30950677  5.1682533\n",
       "6 -1.64164290 -4.0566385"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X=rnorm(20)\n",
    "Y = 2*X+X^2+0.6*X^3+rnorm(20)\n",
    "df = data.frame(X, Y)\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>2.5 %</th><th scope=col>97.5 %</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>-1.1396592 </td><td>-0.01312149</td></tr>\n",
       "\t<tr><th scope=row>X</th><td> 0.9334383 </td><td> 3.42163117</td></tr>\n",
       "\t<tr><th scope=row>I(X^2)</th><td> 0.5351249 </td><td> 1.51890494</td></tr>\n",
       "\t<tr><th scope=row>I(X^3)</th><td> 0.1749300 </td><td> 0.97235379</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & 2.5 \\% & 97.5 \\%\\\\\n",
       "\\hline\n",
       "\t(Intercept) & -1.1396592  & -0.01312149\\\\\n",
       "\tX &  0.9334383  &  3.42163117\\\\\n",
       "\tI(X\\textasciicircum{}2) &  0.5351249  &  1.51890494\\\\\n",
       "\tI(X\\textasciicircum{}3) &  0.1749300  &  0.97235379\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 2.5 % | 97.5 % |\n",
       "|---|---|---|\n",
       "| (Intercept) | -1.1396592  | -0.01312149 |\n",
       "| X |  0.9334383  |  3.42163117 |\n",
       "| I(X^2) |  0.5351249  |  1.51890494 |\n",
       "| I(X^3) |  0.1749300  |  0.97235379 |\n",
       "\n"
      ],
      "text/plain": [
       "            2.5 %      97.5 %     \n",
       "(Intercept) -1.1396592 -0.01312149\n",
       "X            0.9334383  3.42163117\n",
       "I(X^2)       0.5351249  1.51890494\n",
       "I(X^3)       0.1749300  0.97235379"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = lm(Y~X+I(X^2)+I(X^3), data=df)\n",
    "confint(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = Y ~ X + I(X^2) + I(X^3), data = df)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-1.6461 -0.4081 -0.1458  0.4246  2.1160 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  -0.5764     0.2657  -2.169 0.045470 *  \n",
       "X             2.1775     0.5869   3.710 0.001900 ** \n",
       "I(X^2)        1.0270     0.2320   4.426 0.000424 ***\n",
       "I(X^3)        0.5736     0.1881   3.050 0.007639 ** \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.9701 on 16 degrees of freedom\n",
       "Multiple R-squared:  0.978,\tAdjusted R-squared:  0.9739 \n",
       "F-statistic: 237.1 on 3 and 16 DF,  p-value: 1.812e-13\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>2.5 %</th><th scope=col>97.5 %</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td> 1.8172327</td><td> 2.736903 </td></tr>\n",
       "\t<tr><th scope=row>poly(X, 3)1</th><td>22.5039022</td><td>26.616793 </td></tr>\n",
       "\t<tr><th scope=row>poly(X, 3)2</th><td> 5.5220314</td><td> 9.634923 </td></tr>\n",
       "\t<tr><th scope=row>poly(X, 3)3</th><td> 0.9022406</td><td> 5.015132 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & 2.5 \\% & 97.5 \\%\\\\\n",
       "\\hline\n",
       "\t(Intercept) &  1.8172327 &  2.736903 \\\\\n",
       "\tpoly(X, 3)1 & 22.5039022 & 26.616793 \\\\\n",
       "\tpoly(X, 3)2 &  5.5220314 &  9.634923 \\\\\n",
       "\tpoly(X, 3)3 &  0.9022406 &  5.015132 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 2.5 % | 97.5 % |\n",
       "|---|---|---|\n",
       "| (Intercept) |  1.8172327 |  2.736903  |\n",
       "| poly(X, 3)1 | 22.5039022 | 26.616793  |\n",
       "| poly(X, 3)2 |  5.5220314 |  9.634923  |\n",
       "| poly(X, 3)3 |  0.9022406 |  5.015132  |\n",
       "\n"
      ],
      "text/plain": [
       "            2.5 %      97.5 %   \n",
       "(Intercept)  1.8172327  2.736903\n",
       "poly(X, 3)1 22.5039022 26.616793\n",
       "poly(X, 3)2  5.5220314  9.634923\n",
       "poly(X, 3)3  0.9022406  5.015132"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = lm(Y~poly(X,3), data=df)\n",
    "confint(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = Y ~ poly(X, 3), data = df)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-1.6461 -0.4081 -0.1458  0.4246  2.1160 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)   2.2771     0.2169  10.498 1.39e-08 ***\n",
       "poly(X, 3)1  24.5603     0.9701  25.318 2.46e-14 ***\n",
       "poly(X, 3)2   7.5785     0.9701   7.812 7.53e-07 ***\n",
       "poly(X, 3)3   2.9587     0.9701   3.050  0.00764 ** \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.9701 on 16 degrees of freedom\n",
       "Multiple R-squared:  0.978,\tAdjusted R-squared:  0.9739 \n",
       "F-statistic: 237.1 on 3 and 16 DF,  p-value: 1.812e-13\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least if to consider poly function the confidence intervals are wider for the same error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gauss–Markov theorem:\n",
    "(a) Prove the Gauss–Markov theorem: the least squares estimate of a\n",
    "parameter $a^T$β has variance no bigger than that of any other linear\n",
    "unbiased estimate of $a^T$β (Section 3.2.2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let take estimater which differs from least square estimator by bector $b^T$. So that\n",
    "\n",
    "$E(c^T Y) = E(a^T\\beta+b^TY) = E(a^T\\beta) + E(b^tX\\beta)$\n",
    "\n",
    "because we have unbias estimator \n",
    "\n",
    "$=a^T\\beta$ Eq.(3.18)\n",
    "\n",
    "$b^TX = 0$, taking this into account to remove cross products\n",
    "\n",
    "$(c^Ty) = c^TVar(y)c = \\sigma^2 c^Tc = Var(a^T\\beta - b^TY)(a^T \\beta - b^TY)^T = \\sigma^2 (a^Ta/(X^TX)+b^Tb) > Var(a^T\\beta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) The matrix inequality B =< A holds if A − B is positive semidefinite.\n",
    "Show that if $\\hat{V}$ is the variance-covariance matrix of the least squares\n",
    "estimate of β and $V$ is the variance-covariance matrix of any other\n",
    "linear unbiased estimate, then $\\hat{V} =< V$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive semidefinite $X^T(A-B)X >= 0$ for any real X. $\\hat{V} = E(a^T\\beta a\\beta^T)-E(a^T\\beta)E(a\\beta^T)$, $V = E(c^T\\beta c\\beta^T)-E(c^T\\beta)E(c\\beta^T)$ from part (a) = $\\hat{V}+E(b^Tb)>=\\hat{V}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show how the vector of least squares coefficients can be obtained\n",
    "from a single pass of the Gram–Schmidt procedure (Algorithm 3.1). Represent\n",
    "your solution in terms of the QR decomposition of X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By definition $\\beta=X^TY/(XX^{T})$, $x_j =z_j + \\sum_{k=1}^{j-1} \\gamma_{jk}z_k $ or $X=Z\\Gamma$\n",
    "\n",
    "QR dicomposition: $X=QR$, where Q is orthogonal matrix, R is upper triangular matrix, Z=QD, $\\Gamma=D^{-1}R$, D is diagonal matrix.\n",
    "\n",
    "$\\beta = Q^TR^TY/(QRQ^{T}R^{T})=Q^TY/R$\n",
    "\n",
    "Using that R is upper triangular matrix (see also wiki QR decomposition)\n",
    "$r_{pp}\\beta_{p} = <q_{p}, y>$\n",
    "\n",
    "$\\beta_{p} = <z_p, y>/||z_{p}||^2$\n",
    "\n",
    "Substituting back for equation for $\\beta_j$,\n",
    "\n",
    "$r_{p-1, p-1}\\beta_{p-1} +r_{p-1, p}\\beta_p=<q_p, y>$  \n",
    "\n",
    "$\\beta_{p-1} +\\gamma_{p-1,p}\\beta_p=<z_{p-1}, y>/||z_{p-1}||^2$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the ridge regression problem (3.41). Show that this problem\n",
    "is equivalent to the problem\n",
    "\n",
    "$\\hat{\\beta^c}= argmin_{\\beta_c}{(\\sum_{i=1}^{N}(y_i-\\beta_0^c-\\sum_{j=1}^p(x_{ij}-\\bar{x}_j)\\beta^c_j)^2+\\lambda\\sum_{j=1}^p\\beta_j^{c2})}$\n",
    "\n",
    "Give the correspondence between βc and the original β in (3.41). Characterize\n",
    "the solution to this modified criterion. Show that a similar result\n",
    "holds for the lasso.\n",
    "\n",
    "\n",
    "We can write $\\hat{\\beta^c}= argmin_{\\beta_c}{(\\sum_{i=1}^{N}(y_i-(\\beta_0^c-\\sum_{j=1}^p\\bar{x}_{j})-\\sum_{j=1}^px_{ij}\\beta^c_j)^2+\\lambda\\sum_{j=1}^p\\beta_j^{c2})}$\n",
    "\n",
    "$\\beta_0 = \\beta_0^c-\\sum_{j=1}^p\\bar{x}_{j}$, $\\beta_j=\\beta_j^c$ $j>0$\n",
    "\n",
    "It does not depend on regulization term if it does not contain $\\beta_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the ridge regression estimate is the mean (and mode)\n",
    "of the posterior distribution, under a Gaussian prior $\\beta ∼ N(0, \\tau I)$, and\n",
    "Gaussian sampling model $y ∼ N(X\\beta, \\sigma^2I)$. Find the relationship between\n",
    "the regularization parameter λ in the ridge formula, and the variances $\\tau$\n",
    "and $\\sigma^2$.\n",
    "\n",
    "$\\hat{\\beta}_R = X^Ty(X^TX+\\lambda I)^{-1}$\n",
    "\n",
    "From Gaussian distribution:\n",
    "\n",
    "$\\hat{\\beta}_R = argmax_{\\beta}(L(y|\\beta)\\pi(\\beta))$, where L is Gaussian likelyhood, $\\pi(\\beta)$ is probability, $p(\\beta|y)=p(y|\\beta)\\pi(\\beta)$.\n",
    "Taking log from argument\n",
    "\n",
    "$\\hat{\\beta}_R = argmax_{\\beta}(-(y-X\\beta)^T(y-X\\beta)/\\sigma^2-\\beta^T\\beta/\\tau^2)=argmin_{\\beta}((\\beta^TX^TX\\beta-\\beta^TX^Ty-y^TX\\beta)/\\sigma^2+\\beta^T\\beta/\\tau^2)$ \n",
    "\n",
    "If gradient by $\\beta$ in argmin is 0 we have\n",
    "\n",
    "$\\hat{\\beta}_R = X^Ty(X^TX + \\sigma^2/\\tau^2  I)^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This problem is similar or even part of problem 6 where $log(L(y|\\beta)\\pi(\\beta))$ is written by components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the QR decomposition of the uncentered N × (p + 1)\n",
    "matrix X (whose first column is all ones), and the SVD of the N × p\n",
    "centered matrix $\\hat{X}$. Show that Q2 and U span the same subspace, where\n",
    "Q2 is the sub-matrix of Q with the first column removed. Under what\n",
    "circumstances will they be the same, up to sign flips?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q is orthoganal matrix the columns of Q are $q_1, .., q_{p+1}$.  By QR decomposition $span(q_i,... q_j) = span(x_i, ..,x_j), 1<=j<=p+1$ or for Q2 if we shift indexes by -1  $span(q_i,... q_j) = span(x_i, ..,x_j), 1<=j<=p$ (1)\n",
    "\n",
    "We can write $\\hat{x}_i = \\sum_{j<i} a_jq_j$, so $span(q_1, .., q_i)=span(x_1,.., x_i)$ (2)\n",
    "For SVD $span(u_1,.., u_p) = span(\\hat{x}_1,.., \\hat{x}_p)$ (3). Therefore from (1) -(3) $span(q_i,... q_j) = span(u_1,.., u_p)$, Q2 and U span the same subspace.\n",
    "\n",
    "If $\\hat{X}=X$(without first column) they must be the same up to sign flip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
